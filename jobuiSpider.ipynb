{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib2  \n",
    "import random\n",
    "import threading\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from pprint import pprint\n",
    "import sys\n",
    "reload(sys)\n",
    "default_stdout = sys.stdout\n",
    "default_stderr = sys.stderr\n",
    "reload(sys)\n",
    "sys.setdefaultencoding(\"utf-8\")\n",
    "sys.stdout = default_stdout\n",
    "sys.stderr = default_stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#UserAgent\n",
    "uas=[{'User-Agent':'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6'},\\\n",
    "    {'User-Agent':'Mozilla/5.0 (Windows NT 6.2) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.12 Safari/535.11'},\\\n",
    "    {'User-Agent':'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; Trident/6.0)'},\\\n",
    "    {'User-Agent':'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:34.0) Gecko/20100101 Firefox/34.0'},\\\n",
    "    {'User-Agent':'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/44.0.2403.89 Chrome/44.0.2403.89 Safari/537.36'},\\\n",
    "    {'User-Agent':'Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50'},\\\n",
    "    {'User-Agent':'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50'},\\\n",
    "    {'User-Agent':'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0'},\\\n",
    "    {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1'},\\\n",
    "    {'User-Agent':'Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1'},\\\n",
    "    {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_0) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11'},\\\n",
    "    {'User-Agent':'Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; en) Presto/2.8.131 Version/11.11'},\\\n",
    "    {'User-Agent':'Opera/9.80 (Windows NT 6.1; U; en) Presto/2.8.131 Version/11.11'},\n",
    "    {'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.101 Safari/537.36'},\n",
    "    {'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.11 TaoBrowser/2.0 Safari/536.11'},\n",
    "    {'User-Agent':'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; QQDownload 732; .NET4.0C; .NET4.0E; LBBROWSER)\" '}\n",
    "    ]\n",
    "joblisturl='http://www.jobui.com/salary/beijing/'\n",
    "joburl='http://www.jobui.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#get job title and href\n",
    "try:\n",
    "    req = urllib2.Request(joblisturl,headers=uas[random.randint(0,len(uas)-1)])\n",
    "    source = urllib2.urlopen(req,timeout=10).read()\n",
    "    text=unicode(source)\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "except (urllib2.HTTPError, urllib2.URLError), e:\n",
    "    print e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "divs=soup.findAll('div',{'class':'line-job-list j-line-job'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data=[]\n",
    "for div in divs:\n",
    "    areas=div.findAll('div',class_=['job-list-title','j-job-title'])\n",
    "    jobs_=div.findAll('div',class_=['job-select-wrapper'])\n",
    "    i=0\n",
    "    while((i<len(areas))and(i<len(jobs_))):\n",
    "        jobs__=jobs_[i].findAll('a',{'class':'job-name-title'})\n",
    "        for job in jobs__:\n",
    "           data.append({'title':job.text,'area':areas[i].text,'href':str(joburl+job.get('href'))})\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#output all jobs and address\n",
    "header=['title','href','area']\n",
    "with open('jobs.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=header)\n",
    "    writer.writeheader()\n",
    "    for i in data:\n",
    "        writer.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "jobs=data\n",
    "data=[]\n",
    "bad=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for job in jobs:\n",
    "    try:\n",
    "        print 'Capture',job['title']\n",
    "        try:\n",
    "            req = urllib2.Request(job['href'],headers=uas[random.randint(0,len(uas)-1)])\n",
    "            source = urllib2.urlopen(req,timeout=10).read()\n",
    "            text=unicode(source)\n",
    "            soup = BeautifulSoup(text, \"html.parser\")\n",
    "        except (urllib2.HTTPError, urllib2.URLError), e:\n",
    "            print e\n",
    "\n",
    "        scripts=soup.findAll('script',{'type':'text/javascript'})\n",
    "\n",
    "        for script in scripts:\n",
    "            pattern = re.compile(u'[\\u9a8c]\\\\\\',data: \\[(.*?)\\]')\n",
    "            if(re.findall(pattern,script.text)):\n",
    "                list=re.findall(pattern,script.text)[0].split(',')\n",
    "                for i in range(len(list)):\n",
    "                    job['exp_'+str(i)]=int(list[i])\n",
    "            pattern = re.compile(u'[\\u8d44]\\\\\\',data: \\[(.*?)\\]')\n",
    "            if(re.findall(pattern,script.text)):\n",
    "                list=re.findall(pattern,script.text)[0].split(',')\n",
    "                for i in range(len(list)):\n",
    "                    job[str(2016-len(list)+i+1)]=int(list[i])\n",
    "        data.append(job)\n",
    "    except e:\n",
    "        bad.append(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#output the the webpage that unable to captured to recaptured or pass if pages is 404 or corrupts\n",
    "header=['title','href','area']\n",
    "with open('bad.csv', 'wb') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=header, dialect='excel')\n",
    "    writer.writeheader()\n",
    "    for i in bad:\n",
    "        writer.writerow(i)\n",
    "#output the salary to the scv file \n",
    "header=['title','href','area','exp_0','exp_1','exp_2','exp_3','exp_4','exp_5','2009','2010','2011','2012','2013','2014','2015','2016']\n",
    "with open('wage.csv', 'wb') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=header, dialect='excel')\n",
    "    writer.writeheader()\n",
    "    for i in data:\n",
    "        writer.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
