{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib2  \n",
    "import random\n",
    "import threading\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import dbbase\n",
    "from dbbase import session,Dist,MDist,Cell,Record\n",
    "import sys\n",
    "import time\n",
    "reload(sys)\n",
    "sys.setdefaultencoding(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#UserAgent\n",
    "uas=[{'User-Agent':'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6'},\\\n",
    "    {'User-Agent':'Mozilla/5.0 (Windows NT 6.2) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.12 Safari/535.11'},\\\n",
    "    {'User-Agent':'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; Trident/6.0)'},\\\n",
    "    {'User-Agent':'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:34.0) Gecko/20100101 Firefox/34.0'},\\\n",
    "    {'User-Agent':'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/44.0.2403.89 Chrome/44.0.2403.89 Safari/537.36'},\\\n",
    "    {'User-Agent':'Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50'},\\\n",
    "    {'User-Agent':'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50'},\\\n",
    "    {'User-Agent':'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0'},\\\n",
    "    {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1'},\\\n",
    "    {'User-Agent':'Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1'},\\\n",
    "    {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_0) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11'},\\\n",
    "    {'User-Agent':'Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; en) Presto/2.8.131 Version/11.11'},\\\n",
    "    {'User-Agent':'Opera/9.80 (Windows NT 6.1; U; en) Presto/2.8.131 Version/11.11'},\n",
    "    {'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.101 Safari/537.36'},\n",
    "    {'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.11 TaoBrowser/2.0 Safari/536.11'},\n",
    "    {'User-Agent':'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; QQDownload 732; .NET4.0C; .NET4.0E; LBBROWSER)\" '}\n",
    "    ]\n",
    "agent={'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'}\n",
    "#District\n",
    "regions=['haidian']\n",
    "#URL to get cell\n",
    "curl=\"http://bj.lianjia.com/xiaoqu\"\n",
    "#URL to get purchase history\n",
    "phurl=\"http://bj.lianjia.com/chengjiao/c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#get District name and id in lianjia\n",
    "try:\n",
    "    req = urllib2.Request(curl,headers=uas[random.randint(0,len(uas)-1)])\n",
    "    source = urllib2.urlopen(req,timeout=10).read()\n",
    "    text=unicode(source)\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "except (urllib2.HTTPError, urllib2.URLError), e:\n",
    "    print e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dist_list=soup.findAll('div',{'data-role':'ershoufang'})[0].contents[1].find_all('a')\n",
    "dist=[]\n",
    "for distitem in dist_list:\n",
    "    dist.append({'name':distitem.text,'id':str(distitem.get('href').split('/')[2])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.execute(Dist.__table__.insert().prefix_with(' OR IGNORE'),dist)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dist=session.query(Dist).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#get minidistrict name and id for each district in lianjia\n",
    "for distitem in dist:\n",
    "    try:\n",
    "        req = urllib2.Request(curl+'/'+distitem.id+'/',headers=uas[random.randint(0,len(uas)-1)])\n",
    "        source = urllib2.urlopen(req,timeout=10).read()\n",
    "        text=unicode(source)\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "    except (urllib2.HTTPError, urllib2.URLError), e:\n",
    "        print e\n",
    "    mdist_list=soup.findAll('div',{'data-role':'ershoufang'})[0].contents[3].find_all('a')\n",
    "    mdist=[]\n",
    "    for mdistitem in mdist_list:\n",
    "        mdist.append({'id':str(mdistitem.get('href').split('/')[2]), 'name':mdistitem.text, 'dist_id':distitem.id,'cood':''})\n",
    "    session.execute(MDist.__table__.insert().prefix_with(' OR IGNORE'),mdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mdlist=session.query(MDist).all()\n",
    "smdlist=[mdlist[i:i+5] for i in range( 0,len(mdlist),5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(smdlist[45][2].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#the liajia has a decator that give back 404 if request many time in few sec\n",
    "#which means i have to menully do the scrpy wih a poxy i used openvpn in this script\n",
    "for dnum in range(1,2):\n",
    "        for mdlistitem in smdlist[47]:\n",
    "        #get cell information for each minidistrict\n",
    "        #get total pages number\n",
    "            try:\n",
    "                req = urllib2.Request(curl+'/'+mdlistitem.id+'/',headers=uas[random.randint(0,len(uas)-1)])\n",
    "                source = urllib2.urlopen(req,timeout=10).read()\n",
    "                text=unicode(source)\n",
    "                soup = BeautifulSoup(text, \"html.parser\")\n",
    "            except (urllib2.HTTPError, urllib2.URLError), e:\n",
    "                print e\n",
    "            pages=int(json.loads(str(soup.find(\"div\",{\"class\":\"page-box house-lst-page-box\"}).get('page-data')))[u'totalPage'])\n",
    "\n",
    "        #get cell information\n",
    "            for i in range(1,pages+1):\n",
    "                print 'capture cell ',mdlistitem.name,'at page ',i,':',dnum\n",
    "#                time.sleep(random.randint(0,2))\n",
    "                try:\n",
    "                    req = urllib2.Request(curl+'/'+mdlistitem.id+'/pg'+str(i)+'/',headers=uas[random.randint(0,len(uas)-1)])\n",
    "                    source = urllib2.urlopen(req,timeout=10).read()\n",
    "                    text=unicode(source)\n",
    "                    soup = BeautifulSoup(text, \"html.parser\")\n",
    "                except (urllib2.HTTPError, urllib2.URLError), e:\n",
    "                    print e\n",
    "                nebs=soup.find_all(\"li\",{\"class\":\"clear xiaoquListItem\"})\n",
    "                cell=[]\n",
    "                for neb in nebs:\n",
    "                    uid=neb.find(\"div\",{\"class\":\"title\"}).find(\"a\").get('href').split('/')[4]\n",
    "                    name=neb.find(\"div\",{\"class\":\"title\"}).find(\"a\").text\n",
    "                    try:\n",
    "                        price=int(neb.find(\"div\",{\"class\":\"totalPrice\"}).find(\"span\").text)\n",
    "                    except:\n",
    "                        price=0\n",
    "                    try:\n",
    "                        num=int(neb.find(\"a\",{\"class\":\"totalSellCount\"}).find(\"span\").text)\n",
    "                    except:\n",
    "                        num=0\n",
    "                    try:\n",
    "                        traffic=nebs[0].find(\"div\",{\"class\":\"tagList\"}).find('span').text\n",
    "                    except:\n",
    "                        traffic=''\n",
    "                    cell.append({'id':uid,'name':name,\\\n",
    "                                 'avg_price':price, 'onsale_num':num, 'traffic':traffic, 'mdist_id':\\\n",
    "                                 mdlistitem.id})\n",
    "                    session.execute(Cell.__table__.insert().prefix_with(' OR IGNORE'),cell)\n",
    "            session.commit()\n",
    "#            time.sleep(random.randint(10,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "int(neb.find(\"a\",{\"class\":\"totalSellCount\"}).find(\"span\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nebs[0].find(\"div\",{\"class\":\"tagList\"}).find('span').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    req = urllib2.Request(phurl+xiaoqu[0]['id']+'/',headers=uas[random.randint(0,len(uas)-1)])\n",
    "    source = urllib2.urlopen(req,timeout=10).read()\n",
    "    text=unicode(source)\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "except (urllib2.HTTPError, urllib2.URLError), e:\n",
    "    print e\n",
    "#get total pages number\n",
    "pages=int(json.loads(str(soup.find(\"div\",{\"class\":\"page-box house-lst-page-box\"}).get('page-data')))[u'totalPage'])\n",
    "for i in range(1,2):\n",
    "    try:\n",
    "        req = urllib2.Request(curl+'/'+minidist_id[0][0]+'/pg'+str(i)+'/',headers=uas[random.randint(0,len(uas)-1)])\n",
    "        source = urllib2.urlopen(req,timeout=10).read()\n",
    "        text=unicode(source)\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "    except (urllib2.HTTPError, urllib2.URLError), e:\n",
    "        print e\n",
    "    nebs=soup.find_all(\"div\",{\"class\":\"info\"})\n",
    "    for neb in nebs:\n",
    "        info=neb.find(\"div\",{\"class\":\"title\"}).find(\"a\")\n",
    "        xiaoqu.append({'id':info.get('href').split('/')[4],'name':unicode(info.text),'cell_name':unicode(minidist_name[0][0]),'dist_name':unicode(dist_name[0])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
